# 생성형 AI 및 대규모 언어 모델 소개

[![Introduction to Generative AI and Large Language Models](../../images/01-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://youtu.be/vf_mZrn8ibc?WT.mc_id=academic-105485-koreyst)

> *강의 동영상을 보려면 위의 이미지를 클릭하세요.*

생성형 AI는 텍스트, 이미지 및 기타 유형의 콘텐츠를 생성할 수 있는 인공 지능입니다. 이 기술이 환상적인 이유는 누구나 텍스트 프롬프트, 즉 자연어로 작성된 문장만 가지고 사용할 수 있는 AI의 대중화입니다. 가치 있는 작업을 수행하기 위해 Java나 SQL과 같은 언어를 배울 필요 없이, 자신의 언어를 사용하고 원하는 것을 말하면 AI 모델이 제안을 해줍니다. 몇 초 만에 보고서를 작성하거나 이해하고, 애플리케이션을 작성하는 등 그 활용도와 영향력은 엄청납니다.

본 강의에서는 한 가상의 스타트업이 생성형 AI를 활용하여 교육 분야에서의 새로운 비즈니스 기회를 창출하는 방법론과 더불어 해당 방법론의 활용 과정에서 기인하는 사회적 영향 및 기술적 한계와 관련된 불가피한 과제를 해결하는 방법을 살펴봅니다.

## 개요

이 강의에서 다룰 내용은 다음과 같습니다:

* 비즈니스 시나리오 소개: 스타트업 아이디어와 미션.
* 생성형 AI와 현재의 기술 환경에 도달한 방법.
* 대규모 언어 모델의 내부 처리 과정.
* 대규모 언어 모델의 주요 기능 및 실제 사용 사례.

## 학습 목표

이 강의를 마치면 다음과 같은 내용을 이해하게 될 것입니다:

* 생성형 AI의 개념과 대규모 언어 모델의 동작 원리.
* 교육 분야 비즈니스 시나리오를 중심으로 다양한 사용 사례에 대규모 언어 모델을 활용하는 방법.

## 시나리오: 교육분야 가상 스타트업

생성형 AI는 인공지능 기술의 정점으로, 한때 불가능하다고 여겨졌던 것들의 한계를 뛰어넘고 있습니다. 생성형 AI 모델에는 여러 가지 기능과 응용 분야가 있지만, 이번 강의에서는 가상의 스타트업을 통해 교육 분야에 어떤 혁신을 일으키고 있는지 살펴볼 것입니다. 이 스타트업을 *우리 스타트업(our startup)*이라고 부를 것입니다. 우리 스타트업은 다음과 같은 야심 찬 사명감을 가지고 교육 분야에서 일하고 있습니다.

> *전 세계적으로 학습 접근성을 개선하고, 교육에 대한 공평한 접근을 보장하며, 모든 학습자에게 필요에 따라 개인화된 학습 경험을 제공한다.*

우리 스타트업 팀은 현재 가장 강력한 도구 중 하나인 대규모 언어 모델(LLM)을 활용하지 않고는 이 목표를 달성할 수 없다는 것을 잘 알고 있습니다.

생성형 AI는 학생들이 방대한 양의 정보와 예시를 제공하는 가상 교사를 24시간 마음대로 이용할 수 있게 할 수 있고, 교사는 혁신적인 도구를 활용하여 학생을 평가하고 피드백을 제공할 수 있게 하는 등 오늘날 우리가 학습하고 가르치는 방식에 혁신을 가져올 것으로 기대됩니다.

![모니터를 바라보는 다섯 명의 어린 학생 - 이미지: DALLE2](../../images/students-by-DALLE2.png?WT.mc_id=academic-105485-koreyst)

먼저 강의 전반에 걸쳐 사용할 몇 가지 기본 개념과 용어를 정의해 보겠습니다.

## 생성형 AI는 어떻게 만들어졌나?

최근 들어, 생성형 AI 모델의 발표로 인해 엄청난 과대 광고가 쏟아지고 있지만, 이 기술은 60년대에 처음 연구되기 시작한 오래된 기술입니다. 예를 들어, 웹 검색 Bing 대화에 GPT 모델을 사용하는 [OpenAI ChatGPT](https://openai.com/chatgpt) 또는 [Bing Chat](https://www.microsoft.com/edge/features/bing-chat?WT.mc_id=academic-105485-koreyst)에서 볼 수 있듯이, 이제 AI가 인간의 인지 능력을 발휘하는 단계에 이르렀습니다.

조금 더 거슬러 올라가면, 최초의 AI 프로토타입은 전문가 그룹의 지식을 컴퓨터로 표현한 지식베이스에 의존하여 수작업으로 구성된 챗봇이었고, 답변은 입력 텍스트에 나타나는 키워드에 의해 발화되었습니다. 그러나 곧 수작업으로 구축된 챗봇을 사용하는 이러한 접근 방식은 확장성이 떨어진다는 것이 분명해졌습니다.

### AI에 대한 통계적 접근: 머신러닝

90년대에 텍스트 분석에 통계적 접근 방식이 적용되면서 전환점이 찾아왔습니다. 이를 통해 머신러닝(machine learning)이라는 이름으로 알려진 새로운 알고리즘이 개발되었고, 이를 활용하여 명시적으로 프로그래밍하지 않고도 데이터에서 패턴을 학습할 수 있게 되었습니다. 이 접근 방식을 통해 인간의 언어 이해 과정을 기계가 시뮬레이션할 수 있습니다. 통계 모델은 텍스트-레이블 쌍에 대한 학습을 통해 새로운 입력 텍스트를 메시지의 의도를 나타내는 사전 정의된 레이블로 자동 분류할 수 있습니다.

### 신경망과 가상 비서

최근에는 더 많은 양의 데이터와 더 복잡한 연산을 처리할 수 있는 하드웨어 기술의 발전으로 AI 분야의 연구가 활발해지면서 신경망(neural networks) 또는 딥러닝(deep learning) 알고리즘이라고 하는 고급 머신러닝 알고리즘이 개발되었습니다.

신경망(특히 순환 신경망 - Recurrent Neural Networks)은 자연어 처리 성능을 크게 향상시켜 문장에서 단어의 문맥에 집중함으로써 텍스트의 의미를 보다 의미 있게 표현할 수 있게 해줍니다.

이는 새로운 세기의 첫 10년 동안 탄생한 가상 비서의 원동력이 된 기술로, 미리 정의된 스크립트에 따라 응답하거나 타사 서비스를 이용하는 등, 인간의 언어를 해석하고 필요를 파악하여 이를 충족하기 위한 작업을 수행하는 데 매우 능숙하였습니다.

### 현재, 생성형 AI

이것이 바로 딥러닝의 하위 개념으로 볼 수 있는 오늘날의 생성형 AI가 탄생하게 된 배경입니다.

![AI, ML, DL and Generative AI](../../images/AI-diagram.png?WT.mc_id=academic-105485-koreyst)

AI 분야에서 수십 년에 걸친 연구 끝에 *Transformer*라는 새로운 모델 아키텍처가 등장하여 훨씬 더 긴 텍스트 시퀀스를 입력으로 받을 수 있게 됨으로써 RNN의 한계를 극복했습니다. Transformer는 주의 집중 메커니즘에 기반하여 모델의 입력에 서로 다른 가중치를 부여하여 텍스트 시퀀스의 순서에 관계없이 가장 관련성이 높은 정보가 집중된 곳에 '더 많은 주의를 기울일 수 있도록' 합니다.

텍스트 입력과 출력으로 작동하는 이유로 대규모 언어 모델(LLM)이라고도 불리는 최근의 생성형 AI 모델 대부분은 실제로 이 아키텍처를 기반으로 합니다. 책, 기사, 웹사이트 등 다양한 종류의 라벨링되지 않은 방대한 양의 데이터로 학습된 이러한 모델의 흥미로운 점은 다양한 작업에 적용할 수 있고 창의성을 발휘하여 문법적으로 정확한 텍스트를 생성할 수 있다는 것입니다. 따라서 입력 텍스트를 '이해'하는 기계의 능력을 놀라울 정도로 향상시켰을 뿐만 아니라 인간의 언어로 독창적인 응답을 생성할 수 있게 되었습니다.

## 대규모 언어 모델은 어떻게 작동하나요?

다음 장에서 다양한 유형의 생성형 AI 모델을 살펴볼 예정이지만, 지금은 대규모 언어 모델이 어떻게 작동하는지 OpenAI GPT(Generative Pre-trained Transformer) 모델을 중심으로 살펴보기로 하겠습니다.

* **토크나이저, 텍스트를 숫자로 변환**: 대규모 언어 모델은 텍스트를 입력으로 받아 텍스트를 출력으로 생성합니다. 하지만 통계 모델이기 때문에 텍스트 시퀀스보다 숫자에 훨씬 더 잘 작동합니다. 그렇기 때문에 모델에 대한 모든 입력은 핵심 모델에서 사용되기 전에 토크나이저에 의해 처리됩니다. 토큰은 가변적인 길이의 문자들로 구성된 텍스트 덩어리이므로 토크나이저의 주요 작업은 입력을 토큰 배열로 분할하는 것입니다. 그런 다음 각 토큰은 원본 텍스트 청크의 정수 인코딩인 토큰 인덱스와 매핑됩니다.

![Example of tokenization](../../images/tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

* **출력 토큰 예측**: n개의 토큰이 입력으로 주어지면(모델마다 n의 최대값은 다름), 모델은 하나의 토큰을 출력으로 예측할 수 있습니다. 그런 다음 이 토큰은 다음 반복의 입력에 확장 윈도우 패턴으로 통합되어 결국은 한 문장(또는 여러 문장)을 답변으로 얻을 수 있는 더 나은 사용자 경험을 가능하게 합니다. 이것이 바로 ChatGPT를 사용하다가 경험했던, 가끔씩 문장의 중간에 멈추는 것처럼 보이는 현상의 원인을 설명하고 있습니다.

* **선택 프로세스, 확률 분포**: 출력 토큰은 현재 텍스트 시퀀스 이후에 발생할 확률에 따라 모델에 의해 선택됩니다. 이는 모델이 학습을 기반으로 계산된 모든 가능한 '다음 토큰'에 대한 확률 분포를 예측하기 때문입니다. 그러나 결과 분포에서 항상 가장 높은 확률을 가진 토큰이 선택되는 것은 아닙니다. 이 선택에 어느 정도의 무작위성이 추가되어 모델이 비결정적 방식으로 작동하므로 동일한 입력에 대해 정확히 동일한 출력을 얻지 못합니다. 이 정도의 무작위성은 창의적 사고 과정을 시뮬레이션하기 위해 추가되며 temperature라는 모델 매개변수를 사용하여 조정할 수 있습니다.

## 우리 스타트업이 대규모 언어 모델을 어떻게 활용할 수 있나요?

이제 대규모 언어 모델의 내부 동작에 대해 더 잘 이해했으니, 비즈니스 시나리오를 염두에 두고 가장 일반적인 작업을 잘 수행할 수 있는 몇 가지 실제적인 예를 살펴보겠습니다. 대규모 언어 모델의 주요 기능은 *자연어로 작성된 텍스트 입력에서 시작하여 처음부터 텍스트를 생성하는 것*이라고 말씀드렸습니다.

그렇다면 어떤 종류의 텍스트 입력과 출력이 있을까요? 대규모 언어 모델의 입력은 **프롬프트(Prompt)** 라고 하며, 출력은 현재 입력을 완료하기 위해 다음 토큰을 생성하는 모델 메커니즘을 지칭하는 용어인 **완성(completion)** 이라고 합니다. 향후에 프롬프트가 무엇이며 모델을 최대한 활용할 수 있는 방식으로 프롬프트를 설계하는 방법에 대해 자세히 살펴보겠습니다. 하지만 지금은 프롬프트에 다음 내용이 포함될 수 있다고 가정해 보겠습니다:

* 모델에서 기대하는 출력 유형을 지정하는 **인스트럭션(instruction)** 입니다. 이 인스트럭션에는 때때로 몇 가지 예제나 추가 데이터가 포함될 수 있습니다.

    1. 기사, 도서, 제품 리뷰 등을 요약하고 비정형 데이터에서 인사이트를 추출

    ![Example of summarization](../../images/summarization-example.png?WT.mc_id=academic-105485-koreyst)

    <br>

    2. 기사, 에세이, 과제 작성을 위해 창의적인 아이디어와 디자인 제시.

    ![Example of creative writing](../../images/creative-writing-example.png?WT.mc_id=academic-105485-koreyst)

    <br>

* 에이전트와 대화 형식으로 묻는 **질문(question)** 입니다.

![Example of conversation](../../images/conversation-example.png?WT.mc_id=academic-105485-koreyst)

* 작성 **완료해야 할 텍스트(text to complete)** 청크(chunk)로, 암시적으로 글쓰기 지원을 요청하는 것입니다.

![Example of text completion](../../images/text-completion-example.png?WT.mc_id=academic-105485-koreyst)

<br>

* 설명 및 문서화(documentation) 요청과 함께 **코드(code)** 일부가 제시되거나 또는 특정 작업을 수행하는 코드를 생성하도록 요청하는 주석(comment)입니다.

![Coding example](../../images/coding-example.png?WT.mc_id=academic-105485-koreyst)

<br>

위에서 제시된 예시들은 매우 단순하며 대규모 언어 모델 기능의 모든 것을 보여주기 위한 것이 아닙니다. 특히 교육 분야에 국한되지 않고 생성형 AI를 사용할 수 있는 잠재력을 보여주고자 하는 목적입니다.

추가적으로, 생성형 AI 모델의 출력은 완벽하지 않으며 때로는 모델의 창의성이 역으로 작용하여 인간 사용자가 현실을 신비화하거나 불쾌하게 해석할 수 있는 단어의 조합으로 출력될 수 있습니다. 생성형 AI는 비판적이고 창의적인 추론이나 감성 지능을 포함한 보다 포괄적인 지능의 정의에서 볼때는 지능(intelligence)이 아니며, 결정론적이지 않고, 잘못된 참조, 내용 및 진술과 같은 조작이 올바른 정보와 결합되어 설득력 있고 자신감 있는 방식으로 제시될 수 있기 때문에 신뢰할 수 없습니다. 다음 강의에서는 이러한 모든 한계를 다루고 이를 완화하기 위해 무엇을 할 수 있는지 살펴볼 것입니다.

## 과제(Assignment)

당신의 과제는 [생성형 AI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence?WT.mc_id=academic-105485-koreyst)에 대해 자세히 알아보고 현재 생성형 AI가 활용되지는 않지만 이를 적용할 수 있는 새로운 영역을 찾아내는 것입니다. '기존 방식'으로 할 때와 어떤 차이가 있을까요, 이전에는 할 수 없었던 일을 할 수 있을까요, 아니면 더 빨라질까요? 자신이 꿈꾸는 AI 스타트업의 모습에 대해 300단어 요약문을 작성하되 '문제(Problem)', 'AI 사용 방법(How I would use AI)', '영향(Impact)' 등의 헤더(headers)와 사업 계획(business plan)을 포함하세요.

이 작업을 완료했다면 Microsoft의 인큐베이터인 [스타트업 창업자 허브](https://www.microsoft.com/startups?WT.mc_id=academic-105485-koreyst)에 지원할 준비가 되었을 수도 있습니다. Microsoft는 Azure, OpenAI 크레딧과 멘토링 등을 제공합니다.

## Knowledge check

아래 대규모 언어 모델에 대한 내용 중에서 올바른 것은 무엇인가요?

1. 매번 똑같은 응답을 받습니다.
2. 숫자를 추가하고, 작업 코드를 생성하는 등의 작업을 완벽하게 수행합니다.
3. 같은 프롬프트를 사용하더라도 응답이 다를 수 있습니다. 또한 텍스트나 코드 등 초안을 작성하는 데도 유용합니다. 하지만 결과를 개선해야 합니다.

A: 3, LLM은 비결정적이기 때문에 응답이 다양하지만 temperature 설정을 통해 그 차이를 제어할 수 있습니다. 또한 완벽하게 작동할 것이라고 기대해서는 안 되며, 귀찮고 복잡한 작업을 대신 해주기 때문에 처음에 좋은 시도를 하고 점차적으로 개선해야 하는 경우가 많습니다.

## 수고하셨습니다! 여정을 계속합시다.

이 강의를 완료한 후에는 [생성형 AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인하여 생성형 AI 지식의 수준을 계속 높여보세요!

두번째 강좌로 이동하여 [다양한 LLM 유형을 탐색하고 비교](../../../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst)하는 방법을 살펴보세요!